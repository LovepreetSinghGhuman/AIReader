{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3044457717.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    doc_dir = 'C:\\Users\\Lovepreet Singh\\Downloads\\AIReader\\papers'\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from multiprocessing import Lock\n",
    "from typing import List, Dict, Any\n",
    "import argparse\n",
    "\n",
    "import bertopic  # For topic modeling\n",
    "import pandas as pd # For data manipulation\n",
    "import fitz # For PDF text extraction\n",
    "import spacy  # For Dutch and French tokenization\n",
    "from langdetect import detect, LangDetectException  # For language detection\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "from wordsegment import load, segment  # For word segmentation\n",
    "\n",
    "# Path to your directory containing the PDFs\n",
    "doc_dir = './papers'\n",
    "\n",
    "# List to store the blocks of text (as individual records)\n",
    "data = []\n",
    "\n",
    "# Function to check if a line is a heading (all uppercase or starts with 'CHAPTER')\n",
    "def is_heading(line):\n",
    "    return line.isupper() or line.startswith('CHAPTER')\n",
    "\n",
    "# Function to check if a line is a footnote (starts with number in brackets, number, or asterisk)\n",
    "def is_footnote(line):\n",
    "    return re.match(r'^\\[\\d+\\]', line) or re.match(r'^\\d+\\.', line) or line.startswith('*') or line.startswith('Note') or line.startswith('Table') \n",
    "\n",
    "# Function to count words in a block of text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Function to filter out lines containing DOI, URLs, specific keywords, or phrases\n",
    "def contains_doi_or_https(line):\n",
    "    return ('doi' in line.lower() or \n",
    "            'https' in line.lower() or \n",
    "            'http' in line.lower() or \n",
    "            'journal' in line.lower() or \n",
    "            'university' in line.lower() or \n",
    "            'brookville' in line.lower() or\n",
    "            'to cite this article' in line.lower() or\n",
    "            'full terms & conditions' in line.lower() or\n",
    "            'taylor & francis' in line.lower() or\n",
    "            'elsevier' in line.lower() or\n",
    "            'published by' in line.lower() or\n",
    "            'received' in line.lower() or\n",
    "            'revised' in line.lower() or\n",
    "            'author(s)' in line.lower() or\n",
    "            'source:' in line.lower() or\n",
    "            'history:' in line.lower() or\n",
    "            'keywords' in line.lower() or\n",
    "            'vol.' in line.lower() or \n",
    "            'volume' in line.lower() or \n",
    "            'downloaded' in line.lower() or    \n",
    "            'article' in line.lower() or\n",
    "            'creative commons use' in line.lower() or\n",
    "            'author' in line.lower() or \n",
    "            'copyrighted' in line.lower() or\n",
    "            'quarterly' in line.lower() or\n",
    "            'journal' in line.lower() or\n",
    "            'purtell' in line.lower() or\n",
    "            'resources:' in line.lower() or\n",
    "            'publisher' in line.lower() or\n",
    "            'ying' in line.lower() or\n",
    "            'cincinnati' in line.lower() or\n",
    "            'ISSN' in line.lower() or\n",
    "            'All rights reserved' in line.lower() or\n",
    "            'authors' in line.lower())\n",
    "\n",
    "# Function to check if a line is part of the reference or acknowledgements section\n",
    "def is_reference_or_acknowledgements_section(line):\n",
    "    reference_markers = ['references', 'bibliography', 'acknowledgements', 'nederlandse', 'method',\"methods\"]\n",
    "    return any(marker in line.lower() for marker in reference_markers)\n",
    "\n",
    "# Function to replace ligatures with their individual characters\n",
    "def replace_ligatures(text):\n",
    "    ligatures = {\n",
    "        'ﬁ': 'fi',\n",
    "        'ﬂ': 'fl',\n",
    "        'ﬃ': 'ffi',\n",
    "        'ﬄ': 'ffl',\n",
    "        'ﬀ': 'ff',\n",
    "        'ﬂ': 'fl',\n",
    "    }\n",
    "    for ligature, replacement in ligatures.items():\n",
    "        text = text.replace(ligature, replacement)\n",
    "    return text\n",
    "\n",
    "# Function to fix common word splits\n",
    "def fix_common_word_splits(text):\n",
    "    common_fixes = {\n",
    "        'signi ficant': 'significant',\n",
    "        'di fferent': 'different',\n",
    "        'e ffective': 'effective',\n",
    "        'e ffect': 'effect',\n",
    "        'chil dren': 'children',\n",
    "        'e ff ective': 'effective',\n",
    "        'con fi dence': 'confidence',\n",
    "    }\n",
    "    for split_word, correct_word in common_fixes.items():\n",
    "        text = text.replace(split_word, correct_word)\n",
    "    \n",
    "    text = re.sub(r'\\b(\\w{3,})\\s+(\\w{3,})\\b', r'\\1 \\2', text)  # Adjust spaces if needed\n",
    "    return text\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(doc_dir):\n",
    "    if filename.endswith('.pdf'):  # Only process PDF files\n",
    "        file_path = os.path.join(doc_dir, filename)\n",
    "\n",
    "        # Extract the title of the PDF (filename without the '.pdf' extension)\n",
    "        title = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Open the PDF file using PyMuPDF\n",
    "        pdf_document = fitz.open(file_path)\n",
    "\n",
    "        # Flag to indicate if we are in the reference or acknowledgements section for the entire document\n",
    "        section_reached = False\n",
    "\n",
    "        # Iterate through each page in the PDF\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            if section_reached:\n",
    "                break  # Stop processing further pages if the section marker was reached\n",
    "\n",
    "            page = pdf_document.load_page(page_num)  # Load a page by page number\n",
    "            text_dict = page.get_text(\"dict\")  # Extract text in dictionary format to preserve layout\n",
    "            \n",
    "            # Substitute all semicolons (;) with commas (,)\n",
    "            for block in text_dict[\"blocks\"]:\n",
    "                if block[\"type\"] == 0:  # Type 0 is a text block\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            span[\"text\"] = span[\"text\"].replace(';', ',')\n",
    "            \n",
    "            # Process each block of text on the page\n",
    "            for block in text_dict[\"blocks\"]:\n",
    "                if block[\"type\"] == 0:  # Type 0 is a text block\n",
    "                    block_text = \"\"\n",
    "                    prev_x = None  # To store the previous x-coordinate (indentation level)\n",
    "                    paragraph = []  # List to store lines that belong to the same paragraph\n",
    "\n",
    "                    for line in block[\"lines\"]:\n",
    "                        # Get the text from the line\n",
    "                        line_text = \" \".join([span[\"text\"] for span in line[\"spans\"]])\n",
    "\n",
    "                        # Apply ligature replacement and common word fixes\n",
    "                        line_text = replace_ligatures(line_text)\n",
    "                        line_text = fix_common_word_splits(line_text)\n",
    "\n",
    "                        # **Immediately stop processing if the reference/acknowledgements section is detected**\n",
    "                        if is_reference_or_acknowledgements_section(line_text):\n",
    "                            section_reached = True\n",
    "                            break  # Exit the inner loop and stop processing this file\n",
    "                        \n",
    "                        # Skip if it's a header, footnote, contains DOI/URL, or matches the title of the PDF\n",
    "                        if is_heading(line_text) or is_footnote(line_text) or contains_doi_or_https(line_text) or line_text.strip().lower() == title.lower():\n",
    "                            continue\n",
    "\n",
    "                        # Get the x-coordinate (horizontal position of the first word in the line)\n",
    "                        first_word_x = line[\"spans\"][0][\"bbox\"][0]\n",
    "\n",
    "                        # Check if the line belongs to the same paragraph (by horizontal position)\n",
    "                        if prev_x is None or first_word_x - prev_x < 10:  # If the line's x is close to the previous, it's part of the same paragraph\n",
    "                            paragraph.append(line_text)\n",
    "                        else:\n",
    "                            # When indentation changes significantly, treat this as the start of a new paragraph\n",
    "                            if paragraph:  # If there's already accumulated text, store it as a block\n",
    "                                full_paragraph_text = \" \".join(paragraph).strip()\n",
    "                                if count_words(full_paragraph_text) >= 10:  # Skip blocks with less than 10 words\n",
    "                                    data.append([filename, page_num + 1, full_paragraph_text])\n",
    "                            paragraph = [line_text]  # Start a new paragraph\n",
    "\n",
    "                        prev_x = first_word_x  # Update the previous x-coordinate\n",
    "\n",
    "                    # If section_reached is True after breaking, break the outer loop as well\n",
    "                    if section_reached:\n",
    "                        break\n",
    "\n",
    "                    # If there's any accumulated paragraph, add it to the data\n",
    "                    if paragraph and not section_reached:\n",
    "                        full_paragraph_text = \" \".join(paragraph).strip()\n",
    "                        if count_words(full_paragraph_text) >= 10:  # Skip blocks with less than 10 words\n",
    "                            data.append([filename, page_num + 1, full_paragraph_text])\n",
    "\n",
    "# Convert the data to a DataFrame (optional)\n",
    "df = pd.DataFrame(data, columns=[\"File\", \"Page\", \"text\"])\n",
    "\n",
    "# Print the first few records\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
